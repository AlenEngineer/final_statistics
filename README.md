# AnÃ¡lisis de RegresiÃ³n - Dataset Dropout

## ğŸ“Š DescripciÃ³n del Proyecto

Este proyecto implementa un anÃ¡lisis de regresiÃ³n completo para el dataset `dropout.csv`, enfocÃ¡ndose en predecir la "Probabilidad Retirarse (1-5)" usando diferentes modelos de regresiÃ³n. El anÃ¡lisis incluye regresiÃ³n mÃºltiple, lineal simple, curvilÃ­nea y polinomial.

## ğŸ¯ Objetivos

- Analizar factores que influyen en la probabilidad de retirarse de la carrera
- Comparar diferentes modelos de regresiÃ³n
- Identificar las variables mÃ¡s importantes para predecir el abandono acadÃ©mico
- Generar visualizaciones profesionales de los resultados

## ğŸ“ Estructura del Proyecto

```
final/
â”œâ”€â”€ dropout.csv                    # Dataset principal
â”œâ”€â”€ analisis_regresion_completo.py # Script principal de anÃ¡lisis
â”œâ”€â”€ pyproject.toml                # ConfiguraciÃ³n de dependencias
â”œâ”€â”€ README.md                     # Este archivo
â””â”€â”€ *.png                        # GrÃ¡ficos generados
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
- Python 3.8+
- `uv` (gestor de paquetes)

### InstalaciÃ³n
```bash
# Clonar el repositorio (si aplica)
git clone <repository-url>
cd final

# Instalar dependencias con uv
uv add pandas numpy matplotlib seaborn scipy scikit-learn
```

## ğŸ“ˆ Tipos de RegresiÃ³n Implementados

### 1. RegresiÃ³n MÃºltiple
- **Variables predictoras:** 5 variables (Ãndice AcadÃ©mico, EstrÃ©s AcadÃ©mico, SatisfacciÃ³n Carrera, SituaciÃ³n Laboral, Considerado Dejar Carrera)
- **Variable objetivo:** Probabilidad Retirarse (1-5)
- **RÂ²:** 0.598 (59.8% de varianza explicada)
- **Archivo:** `regresion_multiple.png`

### 2. RegresiÃ³n Lineal Simple (SatisfacciÃ³n)
- **Variables:** SatisfacciÃ³n Carrera (1-5) vs Probabilidad Retirarse (1-5)
- **RÂ²:** 0.496 (49.6% de varianza explicada)
- **CorrelaciÃ³n:** r = -0.704 (p < 0.001)
- **InterpretaciÃ³n:** Mayor satisfacciÃ³n â†’ Menor probabilidad de retirarse
- **Archivo:** `regresion_lineal_satisfaccion.png`

### 3. RegresiÃ³n CurvilÃ­nea (Exponencial)
- **Variables:** EstrÃ©s AcadÃ©mico (1-5) vs Probabilidad Retirarse (1-5)
- **Modelo:** y = a * exp(b * x)
- **RÂ²:** 0.443 (44.3% de varianza explicada)
- **ParÃ¡metros:** a=0.571, b=0.361
- **Archivo:** `regresion_curvilinea.png`

### 4. RegresiÃ³n Polinomial (Grado 4)
- **Variables:** Ãndice AcadÃ©mico vs Probabilidad Retirarse (1-5)
- **Modelo:** y = axâ´ + bxÂ³ + cxÂ² + dx + e
- **RÂ²:** 0.222 (22.2% de varianza explicada)
- **Coeficientes:** a=4.200, b=-34.850, c=103.725, d=-130.637, e=60.467
- **Archivo:** `regresion_polinomial_grado4.png`

## ğŸ“Š Resultados Principales

### Ranking de Predictores de Probabilidad Retirarse

| PosiciÃ³n | Variable | RÂ² | CorrelaciÃ³n | InterpretaciÃ³n |
|----------|----------|----|-------------|----------------|
| ğŸ¥‡ **1er** | **SatisfacciÃ³n Carrera** | **0.496** | r = -0.704 | **Mejor predictor** |
| ğŸ¥ˆ **2do** | **EstrÃ©s AcadÃ©mico** | 0.416 | r = 0.645 | RelaciÃ³n positiva fuerte |
| ğŸ¥‰ **3er** | **Ãndice AcadÃ©mico** | 0.133 | r = -0.365 | RelaciÃ³n negativa moderada |

### Modelo General MÃ¡s Efectivo
- **RegresiÃ³n MÃºltiple:** RÂ² = 0.598 (59.8%)
- **Variables utilizadas:** 5 predictoras
- **Mejor modelo para predicciÃ³n general**

## ğŸ¨ GrÃ¡ficos Generados

### Archivos PNG Producidos:
1. **`regresion_multiple.png`** (350KB) - RegresiÃ³n mÃºltiple con 5 variables
2. **`regresion_lineal_satisfaccion.png`** (253KB) - RegresiÃ³n lineal satisfacciÃ³n vs probabilidad retirarse
3. **`regresion_curvilinea.png`** (218KB) - RegresiÃ³n exponencial estrÃ©s vs probabilidad retirarse
4. **`regresion_polinomial_grado4.png`** (285KB) - RegresiÃ³n polinomial Ã­ndice vs probabilidad retirarse
5. **`comparacion_regresiones.png`** (536KB) - GrÃ¡fico comparativo de todos los modelos

### CaracterÃ­sticas de los GrÃ¡ficos:
- âœ… **Banda de confianza** (donde aplica)
- âœ… **EstadÃ­sticas completas** en anotaciones
- âœ… **TÃ­tulos descriptivos** con mÃ©tricas
- âœ… **Etiquetas claras** de ejes
- âœ… **CuadrÃ­cula** para mejor visualizaciÃ³n

## ğŸ”§ Uso del Script

### Ejecutar AnÃ¡lisis Completo
```bash
uv run python analisis_regresion_completo.py
```

### Funciones Principales
- `cargar_datos()`: Carga el dataset dropout.csv
- `preprocesar_datos()`: Codifica variables categÃ³ricas
- `regresion_multiple()`: RegresiÃ³n mÃºltiple con 5 variables
- `regresion_lineal_satisfaccion()`: RegresiÃ³n lineal satisfacciÃ³n vs probabilidad retirarse
- `regresion_curvilinea()`: RegresiÃ³n exponencial
- `regresion_polinomial_grado4()`: RegresiÃ³n polinomial grado 4
- `analisis_adicional()`: Correlaciones y estadÃ­sticas adicionales
- `crear_grafico_comparativo()`: GrÃ¡fico comparativo de modelos

## ğŸ“‹ Variables del Dataset

### Variables NumÃ©ricas:
- **Ãndice AcadÃ©mico:** Rendimiento acadÃ©mico del estudiante
- **Nivel EstrÃ©s AcadÃ©mico (1-5):** Nivel de estrÃ©s percibido
- **SatisfacciÃ³n Carrera (1-5):** SatisfacciÃ³n con la carrera elegida
- **Probabilidad Retirarse (1-5):** Variable objetivo - probabilidad de abandonar

### Variables CategÃ³ricas (Codificadas):
- **SituaciÃ³n Laboral:** Estado laboral del estudiante
- **Financiamiento Estudios:** Tipo de financiamiento
- **Modalidad de Estudio:** Modalidad de estudio
- **Considerado Dejar Carrera:** Frecuencia de considerar abandonar

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### Hallazgos Principales:
1. **La satisfacciÃ³n con la carrera es el factor mÃ¡s importante** para predecir la probabilidad de retirarse (RÂ² = 0.496)
2. **El estrÃ©s acadÃ©mico tiene una relaciÃ³n positiva fuerte** con la probabilidad de retirarse (RÂ² = 0.416)
3. **El Ã­ndice acadÃ©mico tiene una relaciÃ³n negativa moderada** con la probabilidad de retirarse (RÂ² = 0.133)
4. **El modelo mÃºltiple es el mÃ¡s efectivo** para predicciÃ³n general (RÂ² = 0.598)

### Recomendaciones:
- **Mejorar la satisfacciÃ³n estudiantil** es la estrategia mÃ¡s efectiva para reducir el abandono
- **Gestionar el estrÃ©s acadÃ©mico** es crucial para retener estudiantes
- **El rendimiento acadÃ©mico** tiene un impacto moderado en la decisiÃ³n de retirarse

## ğŸ› ï¸ Dependencias

```toml
# pyproject.toml
[project]
dependencies = [
    "pandas>=1.5.0",
    "numpy>=1.21.0",
    "matplotlib>=3.5.0",
    "seaborn>=0.11.0",
    "scipy>=1.9.0",
    "scikit-learn>=1.1.0"
]
```

## ğŸ“ Autor

- **Proyecto:** AnÃ¡lisis de RegresiÃ³n - Dataset Dropout
- **Fecha:** 2024
- **Herramientas:** Python, pandas, matplotlib, seaborn, scikit-learn

## ğŸ“„ Licencia

Este proyecto es para fines educativos y de investigaciÃ³n.

---

**Nota:** Todos los grÃ¡ficos se generan automÃ¡ticamente al ejecutar el script principal. Los archivos PNG contienen visualizaciones profesionales con estadÃ­sticas completas y anotaciones detalladas.
